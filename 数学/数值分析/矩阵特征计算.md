
给定 $A$, 求 $Ax=\lambda x$. 

## 幂法

幂法用于计算矩阵的模最大的特征值和其特征向量. 

这里假设 $A_{n\times n}$ 有 $n$ 个线性无关特征向量 $x_{i}$, 其对应特征值满足: 
$$|\lambda_{1}|>|\lambda_{2}|\geq |\lambda_{3}|\geq \dots\geq |\lambda_{n}|$$

对于非零向量 $u_{0}$, 存在非零数组 $a_{1},a_{2},\dots,a_{n}$ 满足:

$$\begin{array}{c} 
u_{k}=
{A\,u_{k-1}=A^{2}u_{k-2}=\cdots=A^{k}u_{0}=}\\
{\alpha_{1}A^{k}x_{1}+\alpha_{2}A^{k}x_{2}+\cdots+\alpha_{n}A^{k}x_{n}=}\\ 
{\alpha_{1}\lambda_{1}^{k}x_{1}+\alpha_{2}\lambda_{2}^{k}x_{2}+\cdots+\alpha_{n}\lambda_{n}^{k}x_{n}}=\\
{\lambda_{1}^{k}[~\alpha_{1}x_{1}+\alpha_{2}({\frac{\lambda_{2}}{\lambda_{1}}})^{k}{x}_{2}+\cdots+\alpha_{n}({\frac{\lambda_{n}}{\lambda_{1}}})^{k}{x}_{n}~]}
\end{array}$$

*如果 $a_{1}\neq 0$, 当 $k$ 充分大时, 有:* $$u_{k}\approx \lambda_{1}^{k}\alpha_{1}x_{1}$$

因为 $x_{1}$ 是矩阵 $A$ 的特征向量, 那么 $u_{k}$ 也是 $A$ 的特征向量.

### 归一化

为了避免 $u_{k}$ 的模过大 (当 $|\lambda_{1}|>1$) 或过小 (当 $|\lambda_{1}|<1$), 实际计算时, 在每一步对 $u_{k}$ 进行归一化:

$$u_{k}=\frac{Au_{k-1}}{\Vert u_{k-1}\Vert}=\frac{A^{2}u_{k-2}}{\Vert Au_{k-2}\Vert}=\dots=\frac{A^{k}u_{0}}{\Vert A^{k-1}u_{0}\Vert }$$

记: $$u_{k}=\frac{Au_{k-1}}{\Vert u_{k-1}\Vert}=Ay_{k-1}$$

那么 $$y_{k}=\frac{u_{k}}{\Vert u_{k}\Vert}=\frac{A^{k}u_{0}}{\Vert A^{k}u_{0}\Vert }$$

当 $k\to \infty$ 时, 若 $\lambda_{1}>0$, 有 $\large y_{k}\to \frac{\alpha_{1}x_{1}}{\Vert \alpha_{1}x_{1}\Vert}$. 那么 $y_{k}$ 可近似地作为 $A$ 的特征向量.

<br>

如果范数取 *二范数*: 

取 $$\beta_{k}=y_{k-1}^{\top}u_{k}=y_{k-1}^{\top}Ay_{k-1}$$

那么 $$\lim_{ k \to \infty } \beta_{k}=\frac{\alpha_{1}x_{1}^\top}{\Vert \alpha_{1}x_{1}\Vert_{2}}A\frac{\alpha_{1}x_{1}}{\Vert \alpha_{1}x_{1}\Vert_{2}}=\frac{a_{1}^{2}x_{1}^{\top}x_{1}}{\Vert a_{1}x_{1}\Vert_{2}^{2}}\lambda_{1}=\lambda_{1}$$

当 $|\beta_{k}-\beta_{k-1}|/|\beta_{k}|\leq \epsilon$ (允许误差) 时, 迭代终止. 此时 $\beta_{k}$ 作为 $\lambda_{1}$ 近似值, $y_{k-1}$ 作为 $A$ 的近似特征向量.

<br> 

如果范数取 *无限范数*: 

取 $$\beta_{k}=\frac{e_{r}^{\top}u_{k}}{e_{r}^{\top}y_{k-1}}=\frac{e_{r}^{\top}Ay_{k-1}}{e_{r}^{\top}y_{k-1}}$$

其中 $u_{k-1}$ 的第 $r$ 个分量为模最大的分量. $e_{r}$ 是 $n$ 维基本单位向量, 它的第 $r$ 个分量为 $1$, 其余分量为零. 

当 $\large y_{k}\to \frac{\alpha_{1}x_{1}}{\Vert \alpha_{1}x_{1}\Vert}$, 也有 $$\lim_{ k \to \infty }\beta_{k}=\frac{e_{r}^{\top}Ax_{1}}{e_{r}^{\top}x_{1}}$$

### 反幂法

假设非奇异矩阵 $A$ 的特征值满足: $$|\lambda_{1}|\geq|\lambda_{2}|\geq \dots\geq |\lambda_{n-1}|>|\lambda_{n}|$$

要求 $A$ 的模最小的特征值 $\lambda_{n}$ 及特征向量. 

因为 A 非奇异, 因此 $\lambda_{i}\neq 0$. 由 $$Ax_{i}=\lambda_{i}x_{i}$$, 得到 $$A^{-1}x_{i}=\frac{1}{\lambda_{i}}x_{i}$$

此时 $\frac{1}{\lambda_{n}}$ 是 $A^{-1}$ 的按模最大的特征值. 复用上述幂法即可. 反幂法多出了求逆的步骤.

### 移位反幂法

已知 $\lambda_{n}$ 后, 取 $\mu=\lambda_{n}+\epsilon$. 此时反幂法 $(A-\mu I)^{-1}$ 的特征值为 $\lambda'_{i}=\frac{1}{\lambda_{i}-\mu}$. 

此时, $\lambda_{n-1}$ 对应的 $\lambda'$ 最大, 带入幂法中即可求出 $\lambda_{n-1}$. 

<br> 

如果不用移位法, 也可以通过正交投影消除 $\lambda_{n}$ 的影响: $$B=A-\lambda_{n}v_{n}v_{n}^\top$$, 其中 $v_{n}$ 是 $\lambda_{n}$ 对应特征向量, 此时 $B$ 的最小特征值是 $A$ 的次小特征值 ${} \lambda_{n-1} {}$

## Jacobi 

...

## QR 分解法

