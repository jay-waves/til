
给定 $A$, 求 $Ax=\lambda x$. 

## 幂法

幂法用于计算矩阵的模最大的特征值和其特征向量. 

这里假设 $A_{n\times n}$ 有 $n$ 个线性无关特征向量 $x_{i}$, 其对应特征值满足: 
$$|\lambda_{1}|>|\lambda_{2}|\geq |\lambda_{3}|\geq \dots\geq |\lambda_{n}|$$

对于非零向量 $u_{0}$, 存在非零数组 $a_{1},a_{2},\dots,a_{n}$ 满足:

$$\begin{array}{c} 
u_{k}=
{A\,u_{k-1}=A^{2}u_{k-2}=\cdots=A^{k}u_{0}=}\\
{\alpha_{1}A^{k}x_{1}+\alpha_{2}A^{k}x_{2}+\cdots+\alpha_{n}A^{k}x_{n}=}\\ 
{\alpha_{1}\lambda_{1}^{k}x_{1}+\alpha_{2}\lambda_{2}^{k}x_{2}+\cdots+\alpha_{n}\lambda_{n}^{k}x_{n}}=\\
{\lambda_{1}^{k}[~\alpha_{1}x_{1}+\alpha_{2}({\frac{\lambda_{2}}{\lambda_{1}}})^{k}{x}_{2}+\cdots+\alpha_{n}({\frac{\lambda_{n}}{\lambda_{1}}})^{k}{x}_{n}~]}
\end{array}$$

*如果 $a_{1}\neq 0$, 当 $k$ 充分大时, 有:* $$u_{k}\approx \lambda_{1}^{k}\alpha_{1}x_{1}$$

因为 $x_{1}$ 是矩阵 $A$ 的特征向量, 那么 $u_{k}$ 也是 $A$ 的特征向量.

### 归一化

为了避免 $u_{k}$ 的模过大 (当 $|\lambda_{1}|>1$) 或过小 (当 $|\lambda_{1}|<1$), 实际计算时, 在每一步对 $u_{k}$ 进行归一化:

$$u_{k}=\frac{Au_{k-1}}{\Vert u_{k-1}\Vert}=\frac{A^{2}u_{k-2}}{\Vert Au_{k-2}\Vert}=\dots=\frac{A^{k}u_{0}}{\Vert A^{k-1}u_{0}\Vert }$$

记: $$u_{k}=\frac{Au_{k-1}}{\Vert u_{k-1}\Vert}=Ay_{k-1}$$

那么 $$y_{k}=\frac{u_{k}}{\Vert u_{k}\Vert}=\frac{A^{k}u_{0}}{\Vert A^{k}u_{0}\Vert }$$

当 $k\to \infty$ 时, 若 $\lambda_{1}>0$, 有 $\large y_{k}\to \frac{\alpha_{1}x_{1}}{\Vert \alpha_{1}x_{1}\Vert}$. 那么 $y_{k}$ 可近似地作为 $A$ 的特征向量.

<br>

如果范数取 *二范数*: 

取 $$\beta_{k}=y_{k-1}^{\top}u_{k}=y_{k-1}^{\top}Ay_{k-1}$$

那么 $$\lim_{ k \to \infty } \beta_{k}=\frac{\alpha_{1}x_{1}^\top}{\Vert \alpha_{1}x_{1}\Vert_{2}}A\frac{\alpha_{1}x_{1}}{\Vert \alpha_{1}x_{1}\Vert_{2}}=\frac{a_{1}^{2}x_{1}^{\top}x_{1}}{\Vert a_{1}x_{1}\Vert_{2}^{2}}\lambda_{1}=\lambda_{1}$$

当 $|\beta_{k}-\beta_{k-1}|/|\beta_{k}|\leq \epsilon$ (允许误差) 时, 迭代终止. 此时 $\beta_{k}$ 作为 $\lambda_{1}$ 近似值, $y_{k-1}$ 作为 $A$ 的近似特征向量.

<br> 

如果范数取 *无限范数*: 

取 $$\beta_{k}=\frac{e_{r}^{\top}u_{k}}{e_{r}^{\top}y_{k-1}}=\frac{e_{r}^{\top}Ay_{k-1}}{e_{r}^{\top}y_{k-1}}$$

其中 $u_{k-1}$ 的第 $r$ 个分量为模最大的分量. $e_{r}$ 是 $n$ 维基本单位向量, 它的第 $r$ 个分量为 $1$, 其余分量为零. 

当 $\large y_{k}\to \frac{\alpha_{1}x_{1}}{\Vert \alpha_{1}x_{1}\Vert}$, 也有 $$\lim_{ k \to \infty }\beta_{k}=\frac{e_{r}^{\top}Ax_{1}}{e_{r}^{\top}x_{1}}$$

### 反幂法

假设非奇异矩阵 $A$ 的特征值满足: $$|\lambda_{1}|\geq|\lambda_{2}|\geq \dots\geq |\lambda_{n-1}|>|\lambda_{n}|$$

要求 $A$ 的模最小的特征值 $\lambda_{n}$ 及特征向量. 

因为 A 非奇异, 因此 $\lambda_{i}\neq 0$. 由 $$Ax_{i}=\lambda_{i}x_{i}$$, 得到 $$A^{-1}x_{i}=\frac{1}{\lambda_{i}}x_{i}$$

此时 $\frac{1}{\lambda_{n}}$ 是 $A^{-1}$ 的按模最大的特征值. 复用上述幂法即可. 反幂法多出了求逆的步骤.

### 移位反幂法

已知 $\lambda_{n}$ 后, 取 $\mu=\lambda_{n}+\epsilon$. 此时反幂法 $(A-\mu I)^{-1}$ 的特征值为 $\lambda'_{i}=\frac{1}{\lambda_{i}-\mu}$. 

此时, $\lambda_{n-1}$ 对应的 $\lambda'$ 最大, 带入幂法中即可求出 $\lambda_{n-1}$. 

<br> 

如果不用移位法, 也可以通过正交投影消除 $\lambda_{n}$ 的影响: $$B=A-\lambda_{n}v_{n}v_{n}^\top$$, 其中 $v_{n}$ 是 $\lambda_{n}$ 对应特征向量, 此时 $B$ 的最小特征值是 $A$ 的次小特征值 $\lambda_{n-1}$

## 盖尔圆盘定理 (Gershgorin Circle)

对于矩阵 $A=(a_{ij})\in \mathbb{C}^{n\times n}$, 定义每一行的*盖尔圆盘*:

$$D_{i}=\set{z\in \mathbb{C}: |z-a_{ii}|\leq \sum_{j\neq i}|a_{ij}|}$$

定理: **矩阵 $A$ 的所有特征值都包含在所有盖尔圆盘的并集中** $$\large\sigma(A)\subseteq\cup^{n}_{i=1}D_{i}$$

**证明**:

取特征方程 $Ax=\lambda x$ 的最大分量 $x_{k}$, 比较:

$$|\lambda-a_{kk}|=\left|\sum_{j\neq k}a_{kj}x_{j}\right|\leq \sum_{j\neq k}|a_{kj}| | x_{j}|\leq \sum_{j\neq k}|a_{kj}| |x_{k}|$$

消掉 $|x_{k}|$, 得到: 

$$|\lambda-a_{kk}|\leq \sum_{j\neq k}|a_{kj}|$$

$\blacksquare$

### 推论1

**若有一组 $k$ 个盖尔圆盘的并集, 与其余圆盘完全不相交, 则该并集中恰好包含 $k$ 个特征值. (按代数重数计)**.

### 推论2

**若对所有 $i$, 均满足严格对角占优: $$|a_{ii}|>\sum_{j\neq i}|a_{ij}|$$, 则所有圆盘不包含零点, 于是 $0\not\in \sigma(A)$, 矩阵必然可逆.**

## Jacobi 

...

## QR 分解法

### Householder 矩阵

**定义: $H$ 是对称正交矩阵, 满足 $H=I-2vv^{\top}$, 其中 $v$ 是单位向量.**
