### 贝叶斯定理

$$P(A\vert B)=\frac{P(B\vert A)\times P(A)}{P(B)}$$

- P(A) 是**先验概率 (Prior Probability)**, 表示在获得新证据 (B) 之前对某事件发生概率的初始估计.
- P(A|B) 是**后验概率 (Posterior Probability)**, 表示获取新证据 B 之后, 对初始估计进行修正后的概率.
- P(B|A) 是在已知A的条件下B发生的概率, 也被称为似然度 (Likelihood).
- P(B) 是B发生的总概率, 也叫作边缘概率.

贝叶斯定义演化出**贝叶斯决策(推理)理论 (Bayesian Decision Theory)**: 对于 $w_{1}, w_{2},\dots,w_{c}$ 种类别的分类问题, $w_{i}$ 出现的先验概率为 $P(w_{i})$. 如果在特征空间观察到(证据)向量 $\overline{x}=[x_{1}, x_{2},\dots,x_{d}]^{T}$, 且 $P(x\vert w_{i})$ 是已知的, 那么可以得到 $w_{i}$ 出现的后验概率为: $$P(w_{i}\vert \overline{x})=\frac{P(\overline{x}\vert w_{i})P(w_{i})}{\sum^{n}_{j=1}P(\overline{x}\vert w_{j})P(w_{j})}$$ 基于最小错误率的贝叶斯决策规则为: **如果 $P(w_{i}\vert \overline{x})=max_{j=1,2,\dots,c}P(w_{j}\vert \overline{x})$, 那么 $\overline{x}\in w_{i}$**

### 贝叶斯公式的全概率展开

$$P(B|A) =\frac{P(A\cdot B)}{P(A)}=\frac{P(A|B)P(B)}{P(A)}$$

其中 P(A) 即观测事件 A 的概率, 可以通过**全概率公式:** $P(A) = \sum_{i} P(A|B_i)P(B_i)$ 展开. 其中 $B_{i}$ 是一组互斥且完备的事件 (即 $B_{i}$ 的并集是整个样本空间, 且任意两事件不可能同时发生). 

得到:

$$P(B_j|A) = \frac{P(A|B_j)P(B_j)}{\sum_{i} P(A|B_i)P(B_i)}$$

### 似然度

**似然度 (likelihood)** 是一个衡量模型下观测到的数据出现的相对可能性的函数, 其关心的是对 $\theta$ 的评估. $L(\theta\vert x)$ 是参数 $\theta$ 的函数, 而一组观测数据 x 已经给定. (概率则是固定参数, 改变数据).

**最大似然估计** (Maximum Likelihood Estimation, MLE):

有数据集 $X=\{x_{1},x_2,...,x_n\}$, 每个数据点 $x_{i}$ 的概率密度函数为 $f(x_{i}\vert \theta)$, 似然函数为: $$L(\theta|X) = \prod_{i=1}^{n} f(x_i|\theta)$$ 最大似然估计就是找到使 $L(\theta\vert X)$ 最大的 $\theta$ 值, 即给 $L$ 找一个最合理的参数, 使得其最可能观测到该组数据 $X$.

为了便于数学处理, 通常取对数. 两者单调性一致:
$$l(\theta|X) = \ln(L(\theta|X)) = \sum_{i=1}^{n} \ln(f(x_i|\theta))$$
