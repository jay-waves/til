### 贝叶斯定理

$$P(A\vert B)=\frac{P(B\vert A)\times P(A)}{P(B)}$$

- P(A) 是**先验概率 (Prior Probability)**, 表示在获得新证据 (B) 之前对某事件发生概率的初始估计.
- P(A|B) 是**后验概率 (Posterior Probability)**, 表示获取新证据 B 之后, 对初始估计进行修正后的概率.
- P(B|A) 是在已知A的条件下B发生的概率, 也被称为似然度 (Likelihood).
- P(B) 是B发生的总概率, 也叫作边缘概率.

贝叶斯定义演化出**贝叶斯决策(推理)理论 (Bayesian Decision Theory)**: 对于 $w_{1}, w_{2},\dots,w_{c}$ 种类别的分类问题, $w_{i}$ 出现的先验概率为 $P(w_{i})$. 如果在特征空间观察到(证据)向量 $\overline{x}=[x_{1}, x_{2},\dots,x_{d}]^{T}$, 且 $P(x\vert w_{i})$ 是已知的, 那么可以得到 $w_{i}$ 出现的后验概率为: $$P(w_{i}\vert \overline{x})=\frac{P(\overline{x}\vert w_{i})P(w_{i})}{\sum^{n}_{j=1}P(\overline{x}\vert w_{j})P(w_{j})}$$ 基于最小错误率的贝叶斯决策规则为: **如果 $P(w_{i}\vert \overline{x})=max_{j=1,2,\dots,c}P(w_{j}\vert \overline{x})$, 那么 $\overline{x}\in w_{i}$**

### 贝叶斯公式的全概率展开

$$P(B|A) =\frac{P(A\cdot B)}{P(A)}=\frac{P(A|B)P(B)}{P(A)}$$

其中 P(A) 即观测事件 A 的概率, 可以通过**全概率公式:** $P(A) = \sum_{i} P(A|B_i)P(B_i)$ 展开. 其中 $B_{i}$ 是一组互斥且完备的事件 (即 $B_{i}$ 的并集是整个样本空间, 且任意两事件不可能同时发生). 

得到:

$$P(B_j|A) = \frac{P(A|B_j)P(B_j)}{\sum_{i} P(A|B_i)P(B_i)}$$

