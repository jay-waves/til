## 读入
### 文件打开方式
1. `"r"`或`"t"`文本方式读入
- 文本读入行末字符会自动进行系统转化, 如: windows下\\r\\n会被转化为\\n
- 部分字符可能会被直接转化为乱码, 不能正常转义(少见)
2. `"b"`二进制方式读入
- 纯二进制读入不会进行\\r\\n的转化, 所以可能造成多读入\\r的情况
- 可以处理多种文件, 如图片视频等格式, 本质也只是二进制码, 一样可以进行处理
#### 读入实现
- 函数读入文件的速度大概是`read>fread>fgets`
- 下面实现一种用fread读入整个文件的片段如string中:
```c
	FILE *fp;
	long long size;
	char *buffer, *p;
	fp = fopen( "file.path", "rb+" );
//必须使用二进制读入, 否则fread很可能读不全整个文章(末尾可能莫名其妙被截断), 但如此\r\n会全部读入
	fseek( fp, 0, SEEK_END );
	size = ftell( fp );
	rewind( fp );

	//malloc memory of whole file
	buffer = ( char * )malloc( sizeof( char * ) * size );
	fread( buffer, size, 1, fp );
	//do sth
	fclose( fp );
	free( buffer );
```
### 特殊字符编码处理
==现在文本远不止128位, 如汉字等一定是多字节字符, 用char类型会溢出==
#### utf-8详解
传统anscii文件形式从一字节转为三字节时, 对于英语字符等不需要这么多位(bit)的字符, 采取的处理是高位置0. 但这造成了空间大量浪费. utf-8编码格式则不同, 它的字符宽度涵盖1,2,3字节, 对于单字节不做处理, 对于2,3字节字符对字符每字节(byte)的高位(bit)进行了标识处理, 具体不解释, 最终要的是前两高位字节(first two bytes)的最高位(bit)都标识为1(还有其他标识). 这导致了, 如果按单字节读取的话, 字节一定是负的, 利用这一一点就可以很好的让我们辨识出多字节字符和单字节字符(通常为字母数字等常用字符)
#### 处理方式
1. 用`fgetc()`函数, 其返回值为`int`, 也就是说它可以自动识别出单字节还是多字节, 并返回int
- 返回`int`是因为多字节`char`放不下, `unsigned char`也放不下, 如文件末尾标识符`EOF(-1)`就不能用`unsigned char`表示出来
- 用int就可以解决问题: 
> 文档内部可能存在多字节中的0x0000FFF, 如果仅用char读入的话, 会被截断为0xFFF(就是EOF,-1), 造成误判文档结束
> 同时还能直接判断文档内多文档字符